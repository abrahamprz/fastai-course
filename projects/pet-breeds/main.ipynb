{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q --upgrade pip\n",
    "%pip install -q fastai\n",
    "%pip install -q fastbook nbdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Pets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to extract the breed of each pet from each image. For this, we need to understand how the data is laid out in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the content of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset provides *images* and *annotations* directories. The source website states that the *annotations* directory contains information about what the pets are instead of what they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project focuses on classification, not localization. This *annotation* information is **not useful for this project**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on the *images* directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(path/\"images\").ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the filenames appears to be:\n",
    "- pet breed\n",
    "- underscore\n",
    "- number\n",
    "- file extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project will require to extract the breed from the filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't make too many assumptions. Some breeds have multiple words, so we cannot assume that the breed is located before the first underscore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick one of these filenames to test our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = (path/\"images\").ls()[0]\n",
    "fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to extract the breed is to use a *regular expression*, also known as *regex*. We need a regex that extracts the breed from the filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the ```findall``` methos to try a regex against the filename of the ```fname``` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'(.+)_\\d+.jpg$', fname.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we confirmed that the regex works, let's use it to label the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```RegexLabeller``` class is used for labeling with regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = DataBlock(\n",
    "    blocks = (ImageBlock, CategoryBlock),\n",
    "    get_items = get_image_files, \n",
    "    splitter = RandomSplitter(seed=42), \n",
    "    get_y = using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'), \n",
    "    item_tfms = Resize(460), \n",
    "    batch_tfms = aug_transforms(size=224, min_scale=0.75)\n",
    ")\n",
    "\n",
    "dls = pets.dataloaders(path/\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines implement the fastai data augmentation strategy called *presizing*. \n",
    "\n",
    "```python\n",
    "    item_tfms = Resize(460), \n",
    "    batch_tfms = aug_transforms(size=224, min_scale=0.75))\n",
    "```\n",
    "\n",
    "This is a technique that minimizes the data destruction while maintaining good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and Debugging a DataBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Never assume that the code is working perfectly.\n",
    "- Even if the code works, there's no guarantee that the template will work with the data source as intended.\n",
    "- Always check your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With fastai the data can be checked using the ```show_batch``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(nrows=1, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```summary``` method provides a summary of the data. This can be useful to check if the data is being processed as expected. For instance, one common mistake is to forget to use a ```Resize``` transform, which can lead to a mismatch in the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to use the ```summary``` method to check the data following the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pets1 = DataBlock(\n",
    "#     blocks = (ImageBlock, CategoryBlock),\n",
    "#     get_items = get_image_files,\n",
    "#     splitter = RandomSplitter(seed=42),\n",
    "#     get_y = using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "# )\n",
    "\n",
    "# pets1.summary(path/\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data looks right, it can be used to train a **simple** model. This is important because it helps to know the baseline results. \n",
    "- Perhaps the problem doesn't require a lot of domain-specific engineering.\n",
    "- Perhaps the data doesn't seem to train the model at all.\n",
    "\n",
    "These are things you want to know **as soon as possible**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "# UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous shows the result of each epoch of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COLUMNS**\n",
    "- **epoch:** *complete pass through the dataset.*\n",
    "- **train_loss:** *loss over the items of the training set.*\n",
    "- **valid_loss:** *loss over the items of the validation set.*\n",
    "- **error_rate:** *error rate over the items of the validation set.*\n",
    "- **time:** *time taken for the epoch.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the line of code \n",
    "```python \n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "``` \n",
    "selects the error rate as the metric to be used. It's an optional parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*loss* can be any function decided to optimize the parameters of the model. In thuis case, due to the image data and the classification problem, the loss function selected by fastai is *cross-entropy loss*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross-entropy loss*** has two benefits:\n",
    "- Works even when the dependent variable is not binary.\n",
    "- Results in a faster and more reliable training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get a batch of the real data from ```DataLoarders``` with the ```one_batch``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous line of code returns the *dependent* (y) and *independent* (x) variables of the first batch of the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch size is 64, so the first batch has 64 items. This also means that we have 64 rows in this tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row is an integer between 0 and 36. This is the index of the predicted class (pet breed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions can be viewed using the ```Learner.get_preds``` method. This method takes either a dataset index (0 for train and 1 for valid) or an iterator of batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(dl=[(x, y)])\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are 37 probabilities between 0 and 1, which add up to 1 in total. These are the probabilities of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds[0]), preds[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform the activations of the model into predictions like the ones we saw before, we need to apply the *softmax* function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classification model, the softmax activation function in the final layer is used to ensure that the activations are between 0 and 1 and that they add up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_function(torch.sigmoid, min=-4, max=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
